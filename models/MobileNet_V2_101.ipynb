{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNcWnhBNC/o4vssxBv1VzLm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itspallavi20/Oral_Diseases_Prediction/blob/main/models/MobileNet_V2_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "a50La3PDo7aA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db53ed0-3d31-4920-866c-32da9cacb1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/Oral_Diseases_Project/Dataset/Train'\n",
        "val_dir = '/content/drive/MyDrive/Oral_Diseases_Project/Dataset/Validation'"
      ],
      "metadata": {
        "id": "ABEPsB0lQ_z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "img_size = 224\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMYkexHY7P03",
        "outputId": "73a42012-2fd7-4cba-e6cf-8ab28dc29dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Found 1479 images belonging to 6 classes.\n",
            "Found 300 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_steps=len(val_generator)\n",
        ")\n",
        "\n",
        "base_model.trainable = True\n",
        "fine_tune_at = 100\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune the model\n",
        "history_finetune = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_steps=len(val_generator)\n",
        ")\n",
        "\n",
        " #The model after training\n",
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHN08xmM6tTN",
        "outputId": "266ff662-c0cb-49a6-a275-400a8fe5f1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3s/step - accuracy: 0.9532 - loss: 0.1472 - val_accuracy: 0.0400 - val_loss: 6.6024\n",
            "Epoch 2/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3s/step - accuracy: 0.9656 - loss: 0.1331 - val_accuracy: 0.0400 - val_loss: 6.7339\n",
            "Epoch 4/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 125ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - accuracy: 0.9699 - loss: 0.1275 - val_accuracy: 0.0367 - val_loss: 6.8317\n",
            "Epoch 6/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3s/step - accuracy: 0.9787 - loss: 0.0929 - val_accuracy: 0.0367 - val_loss: 6.9133\n",
            "Epoch 8/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.9757 - loss: 0.1000 - val_accuracy: 0.0300 - val_loss: 6.9275\n",
            "Epoch 10/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 1/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3s/step - accuracy: 0.9698 - loss: 0.1062 - val_accuracy: 0.0267 - val_loss: 6.9990\n",
            "Epoch 2/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3s/step - accuracy: 0.9880 - loss: 0.0717 - val_accuracy: 0.0267 - val_loss: 7.1440\n",
            "Epoch 4/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3s/step - accuracy: 0.9817 - loss: 0.0816 - val_accuracy: 0.0267 - val_loss: 7.1125\n",
            "Epoch 6/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3s/step - accuracy: 0.9863 - loss: 0.0640 - val_accuracy: 0.0233 - val_loss: 7.1957\n",
            "Epoch 8/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.9796 - loss: 0.0772 - val_accuracy: 0.0233 - val_loss: 7.2912\n",
            "Epoch 10/10\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.0241 - loss: 7.2992\n",
            "Validation Loss: 7.291189670562744\n",
            "Validation Accuracy: 0.023333333432674408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_mat = np.array([\n",
        "    [0, 12, 6, 4, 0, 1],\n",
        "    [0, 11, 6, 1, 0, 0],\n",
        "    [0, 34, 10, 10, 1, 2],\n",
        "    [0, 84, 42, 24, 1, 2],\n",
        "    [0, 14, 9, 6, 1, 0],\n",
        "    [0, 12, 3, 4, 0, 0]\n",
        "])\n",
        "\n",
        "num_classes = confusion_mat.shape[0]\n",
        "\n",
        "metrics = {class_label: {\"TP\": 0, \"FP\": 0, \"FN\": 0, \"TN\": 0} for class_label in range(num_classes)}\n",
        "\n",
        "for i in range(num_classes):\n",
        "    metrics[i][\"TP\"] = confusion_mat[i, i]  # Diagonal element is TP\n",
        "    metrics[i][\"FP\"] = np.sum(confusion_mat[:, i]) - confusion_mat[i, i]  # Column sum - TP\n",
        "    metrics[i][\"FN\"] = np.sum(confusion_mat[i, :]) - confusion_mat[i, i]  # Row sum - TP\n",
        "    metrics[i][\"TN\"] = np.sum(confusion_mat) - (metrics[i][\"TP\"] + metrics[i][\"FP\"] + metrics[i][\"FN\"])  # Total sum - (TP + FP + FN)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "print(\"\\nMetrics for Each Class:\")\n",
        "for class_label in range(num_classes):\n",
        "    print(f\"Class {class_label}:\")\n",
        "    print(f\"  TP: {metrics[class_label]['TP']}\")\n",
        "    print(f\"  FP: {metrics[class_label]['FP']}\")\n",
        "    print(f\"  FN: {metrics[class_label]['FN']}\")\n",
        "    print(f\"  TN: {metrics[class_label]['TN']}\")\n",
        "\n",
        "print(\"\\nSensitivity (Recall) and Specificity for Each Class:\")\n",
        "for class_label in range(num_classes):\n",
        "    TP = metrics[class_label][\"TP\"]\n",
        "    FP = metrics[class_label][\"FP\"]\n",
        "    FN = metrics[class_label][\"FN\"]\n",
        "    TN = metrics[class_label][\"TN\"]\n",
        "\n",
        "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0  # Avoid division by zero\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # Avoid division by zero\n",
        "\n",
        "    print(f\"Class {class_label}:\")\n",
        "    print(f\"  Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "    print(f\"  Specificity: {specificity:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vfTVl1fNOWY",
        "outputId": "a13de87f-dbff-4ad4-99e2-48cd0299a82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 0 12  6  4  0  1]\n",
            " [ 0 11  6  1  0  0]\n",
            " [ 0 34 10 10  1  2]\n",
            " [ 0 84 42 24  1  2]\n",
            " [ 0 14  9  6  1  0]\n",
            " [ 0 12  3  4  0  0]]\n",
            "\n",
            "Metrics for Each Class:\n",
            "Class 0:\n",
            "  TP: 0\n",
            "  FP: 0\n",
            "  FN: 23\n",
            "  TN: 277\n",
            "Class 1:\n",
            "  TP: 11\n",
            "  FP: 156\n",
            "  FN: 7\n",
            "  TN: 126\n",
            "Class 2:\n",
            "  TP: 10\n",
            "  FP: 66\n",
            "  FN: 47\n",
            "  TN: 177\n",
            "Class 3:\n",
            "  TP: 24\n",
            "  FP: 25\n",
            "  FN: 129\n",
            "  TN: 122\n",
            "Class 4:\n",
            "  TP: 1\n",
            "  FP: 2\n",
            "  FN: 29\n",
            "  TN: 268\n",
            "Class 5:\n",
            "  TP: 0\n",
            "  FP: 5\n",
            "  FN: 19\n",
            "  TN: 276\n",
            "\n",
            "Sensitivity (Recall) and Specificity for Each Class:\n",
            "Class 0:\n",
            "  Sensitivity (Recall): 0.0000\n",
            "  Specificity: 1.0000\n",
            "Class 1:\n",
            "  Sensitivity (Recall): 0.6111\n",
            "  Specificity: 0.4468\n",
            "Class 2:\n",
            "  Sensitivity (Recall): 0.1754\n",
            "  Specificity: 0.7284\n",
            "Class 3:\n",
            "  Sensitivity (Recall): 0.1569\n",
            "  Specificity: 0.8299\n",
            "Class 4:\n",
            "  Sensitivity (Recall): 0.0333\n",
            "  Specificity: 0.9926\n",
            "Class 5:\n",
            "  Sensitivity (Recall): 0.0000\n",
            "  Specificity: 0.9822\n"
          ]
        }
      ]
    }
  ]
}